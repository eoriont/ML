{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "batch_size = 32\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device\", device)\n",
    "eval_interval = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"input.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5451,\n",
       " 47317,\n",
       " 512,\n",
       " 10438,\n",
       " 584,\n",
       " 10570,\n",
       " 904,\n",
       " 4726,\n",
       " 11,\n",
       " 6865,\n",
       " 757,\n",
       " 6604,\n",
       " 382,\n",
       " 2460,\n",
       " 512,\n",
       " 96945,\n",
       " 11,\n",
       " 6604,\n",
       " 382,\n",
       " 5451,\n",
       " 47317,\n",
       " 512,\n",
       " 2675,\n",
       " 527,\n",
       " 682,\n",
       " 20250,\n",
       " 4856,\n",
       " 311,\n",
       " 2815,\n",
       " 1109,\n",
       " 311,\n",
       " 2138,\n",
       " 819,\n",
       " 1980,\n",
       " 2460,\n",
       " 512,\n",
       " 66494,\n",
       " 13,\n",
       " 20250,\n",
       " 382,\n",
       " 5451,\n",
       " 47317,\n",
       " 512,\n",
       " 5451,\n",
       " 11,\n",
       " 499,\n",
       " 1440,\n",
       " 356,\n",
       " 2192,\n",
       " 355,\n",
       " 2947,\n",
       " 5979,\n",
       " 355,\n",
       " 374,\n",
       " 10388,\n",
       " 9354,\n",
       " 311,\n",
       " 279,\n",
       " 1274,\n",
       " 382,\n",
       " 2460,\n",
       " 512,\n",
       " 1687,\n",
       " 1440,\n",
       " 956,\n",
       " 11,\n",
       " 584,\n",
       " 1440,\n",
       " 956,\n",
       " 382,\n",
       " 5451,\n",
       " 47317,\n",
       " 512,\n",
       " 10267,\n",
       " 603,\n",
       " 5622,\n",
       " 1461,\n",
       " 11,\n",
       " 323,\n",
       " 584,\n",
       " 3358,\n",
       " 617,\n",
       " 14095,\n",
       " 520,\n",
       " 1057,\n",
       " 1866,\n",
       " 3430,\n",
       " 627,\n",
       " 3957,\n",
       " 956,\n",
       " 264,\n",
       " 36543,\n",
       " 1980,\n",
       " 2460,\n",
       " 512,\n",
       " 2822,\n",
       " 810,\n",
       " 7556,\n",
       " 389,\n",
       " 956]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "old_tokens = enc.encode(data)\n",
    "old_tokens[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "old2new = {x:i for i, x in enumerate(set(old_tokens))}\n",
    "new2old = {old2new[i]:i for i in old2new.keys()}\n",
    "tokens = [old2new[x] for x in old_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you know Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us kill him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode([new2old[x] for x in tokens[:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([301829]) torch.int64\n",
      "tensor([ 3488,  7161,   349,  5685,   408,  5738,   678,  3131,     5,  4145,\n",
      "          552,  4028,   233,  1797,   349, 11796,     5,  4028,   233,  3488,\n",
      "         7161,   349,  1922,   360,   493,  8942,  3201,   164,  2015,   844,\n",
      "          164,  1604,   604,  1501,  1797,   349,   723,     7,  8942,   233,\n",
      "         3488,  7161,   349,  3488,     5,   339,  1095,   207,  1639,   206,\n",
      "         2099,  3747,   206,   225,  5666,  5242,   164,   136,   970,   233,\n",
      "         1797,   349,  1285,  1095,   722,     5,   408,  1095,   722,   233,\n",
      "         3488,  7161,   349,  5618,   423,  3568,  1110,     5,   175,   408,\n",
      "         2351,   434,  7008,   354,   798,  1407,  2398,   443,  2695,   722,\n",
      "          121,  2590,  1501,  1797,   349,  2019,   596,  4459,   240,   722,\n",
      "           12,   832,   278,   238,  2063,    11,  2255,     5,  2255,  1687,\n",
      "         7671,  7161,   349,  2763,  2437,     5,  1292,  5710,   233,  3488,\n",
      "         7161,   349,  1285,   360,  5124,  4667,  5710,     5,   136,  2348,\n",
      "         1684,  3504,  1292,   443,  2678,  6095,  1335,  1433,   925,   240,\n",
      "          794,  7680,   423,    11,   269,   600,    94,  4937,  4522,   423,\n",
      "          521,   136,  1711, 10739,   331,     5,  1078,   278,   792,    94,\n",
      "         1011,  4366,   453,     5,   408,  1899,  4702,   600,  8505,   423,\n",
      "         2625,   744,   137,  4772,   600,  1350,   408,   360,  1697, 10233,\n",
      "           11,   136,   351,  8152,   276,    94,  1953, 10109,   423,     5,\n",
      "          136,  1270,   168,   798, 10397,     5,   225,   284,   304,    94,\n",
      "        11973,   164,  2754,   823,   651,  3130,    12,   798,    94,    64,\n",
      "         1572,   496,   225,   121,  5035,   164,   856,  4168,   423,  2958,\n",
      "          267,   294,    94,   263,   138,  6556,     5,  4021,   408,  2558,\n",
      "          281,  1577,    11,   220,   136, 11423,  1095,   209,    94,    64,\n",
      "         9836,   267,   157,  1605,   220,  7776,     5,   370,   157,  8244,\n",
      "          220,  2958,   233,  7671,  7161,   349, 11224,   339,  5738,  3475,\n",
      "         1761,   207,  1639,   206,  2099,  3747,   206,  1501,  1797,   349,\n",
      "         8831,  1110,   889,    11,   395,   419,   121,  1239,  3598,   164,\n",
      "          136,  2880,  5610,   233,  7671,  7161,   349,  3508,   339,   871,\n",
      "         2500,   395,   510,  2063,   220,   599,  2271,  1501,  3488,  7161,\n",
      "          349, 10629,  1269,    12,   175,  1091,   238,  1682,   164,  2148,\n",
      "         1110,  1292,    94,  6331,  6371,     5,   521,   276,   395,  9402,\n",
      "         3597,   294,  1291,  6540,   233,  7671,  7161,   349,    29,   203,\n",
      "            5,   521,  4028,   370,  3988,   249,   233,  3488,  7161,   349,\n",
      "           24,  1529, 11541,   339,     5,   871,   395,  8838,  2063,  8437,\n",
      "            5,   395,  1174,    94,   132,   164,   276,   626,    11,  2491,\n",
      "         4897,  7397,  9468,  3696,  2143,   460,   238,    94,  1389,   164,\n",
      "         1529,   278,   399,   220,   599,  2271,   395,  1174,   278,   164,\n",
      "           94, 11719,   599,  4063,   175,   164,   238, 10963,  6540,    12,\n",
      "          676,   395,    94,   142,     5,  1153,  6410,   136,  2829,   168,\n",
      "          599,  1937,   233,  7671,  7161,   349,  2678,   395,  2865,  1149,\n",
      "          157,   599,  4289,     5,   339,  1981,   121,    94,  1369,   157,\n",
      "         1110,     7,  1119,  1522,   157,   686,  1253,  1529,   395,   225,\n",
      "         9578,   151,   579,   233,  3488,  7161,   349,  1971,   209,  1522,\n",
      "          370,     5,   209,   914,   370,   238, 11328,   168,  2607,   137,\n",
      "          234,  8838, 10183,     5,   294,  4976,     5,   164, 11024,   157,\n",
      "         9356,   443,  2678,  8694,   360,  1150,    15,   402,   772,  2245,\n",
      "          153,     2,   136,  2355,    94,   142,  4949,    11,  2289,  3181,\n",
      "          408,   381,   848,  1226,    15,   164,   136, 12082,  1687,  1797,\n",
      "          349, 11437,     5,  1873,   233,  3488,  7161,   349, 11852,     0,\n",
      "          664,  2800,  1226,  1501,  7671,  7161,   349,    38,  1383,  6011,\n",
      "          125,  5232,  3116,  9689,    46,    12,   616,   276,  8838,  1970,\n",
      "         5695,    94,  1378,   970,   233,  3488,  7161,   349,  1173,   419,\n",
      "          616,  5890,  2379,    11,   794,   493,   136,  2006,   792,   570,\n",
      "         1687,    28,   729,   729,    24,  1569,   349,  2678,   745,   419,\n",
      "            5,   637,  2271,  3654,     5,   157,  1103,    15,  1065,   531,\n",
      "          339,    94,  1767,  5731,   175,  8706,    15,   402,  3285,    15,\n",
      "         4028,     5,   209, 10102,   339,   233,  3488,  7161,   349,  4723,\n",
      "         1888,   225,   370,  5495,   164,   136,  6303,    12,   600,   434,\n",
      "           94, 12011, 10807,  1997,   267,  8518,   335,   871,   408, 11631,\n",
      "          164,   467,   196,  4825,  1107,   408,  2351,  1138,   215,   188,\n",
      "          157,  9438,     7,  1782,  1529,  4667,    94,  4492,   841,   434,\n",
      "         2631,  6220,    64,    11,   600,  3258,  1095,   408,    94,  8743,\n",
      "         2631,  6321,  1697,   233,    28,   729,   729,    24,  1569,   349,\n",
      "         5689,     5,  2548,     5,   637,  1292,  3217,     5,  5790,  5890,\n",
      "         2828,   196,  5571,   339, 11401, 10474,  1501,  3488,  7161,   349,\n",
      "         1285,  2865,     5, 10965,     5,   408,   360,  7087,  1968,   233,\n",
      "           28,   729,   729,    24,  1569,   349,    24,  2360,   339,     5,\n",
      "         3217,     5,  1105,  7665,  1823,    94,  6451,   136,  2348,  1684,\n",
      "         3504,   168,   339,     7,  1357,   508,  4185,   196,  4628,  7677,\n",
      "          157,   267, 10233,   191,     5,   339,   955,   284,  1269,    94,\n",
      "         4609,   354,   136,  9699,   294,   508,   208,  3167,   284,  6389,\n",
      "          856,    94,  8831,   136,  6674,  1223,     5,  4130,  2370,   501,\n",
      "          240,    94,   582,  1253,   278,  3318,     5,  8882,  3704,  7836,\n",
      "         2087,   987,    94,  1631,   596,  2631,  1957,   284,  4733,   844,\n",
      "          460,  2497,    94, 11454,   157,   508,  8196,  2669,     7,  1357,\n",
      "          136, 10233,   191,   196,   582, 11423,     5,   370,   136,  2348,\n",
      "         1684,  3504,     5,   989,   278,     5,   175,    94,  4628, 11850,\n",
      "          164,   856,     5,   370,  6321,     5,  1522,  1149,     7,  1298,\n",
      "          319,   196,  1922,   360,  4523,   386,  7459,   331,    94,   765,\n",
      "         1847,  1065,   596,  5339,   339,     5,   175,   339,   956,    94,\n",
      "          582,  6162,   775,   153,     2,   136,  1223,     5,   664,  1823,\n",
      "          220,   339,   830,  4455,   196,  3064,   339,  4802,   856,   284,\n",
      "         7052,   233,  3488,  7161,   349,   183,   220,   423,     0,  2178,\n",
      "            5,  6702,     0,  1782,   625, 11240,  5514,   220,   423,    94,\n",
      "         7228,    11,  4586,   423,   164,  1604,   604,     5,   175,   651,\n",
      "         2518,  2074,  8970,    94,    48,  1793,  1587,   294, 10133,    12,\n",
      "          989,  1218, 11712,   220,   423,  2399,     5,   164,    94,  9985,\n",
      "          423,  6359,    12,  4621,  4417,   678,  9623,   893,    94,  1313,\n",
      "          147,  1761,   136,  5205,     5,   175,  2438,   596,    94,    61,\n",
      "          981,  3869, 11324,  4417,     5,   164,  5060,   513,   175, 12010,\n",
      "           94,  1378,  4667,     7,  1097,   136, 10416,  4812,   423,   370,\n",
      "          513,     5,   600,   501,    12,   175,    94,  8587,   419,   493,\n",
      "          136,  2139,   600,  6325,   423,   233,    28,   729,   729,    24,\n",
      "         1569,   349,  8148,   339,  1522,    94,  7644,   279, 10474,   145,\n",
      "        11231,  3988,   196,  1671,   238,  6827,   168,  7735,     7,   209,\n",
      "         3258,  2360,   339,    94,    16,  3334,  9959,    11,   278,   955,\n",
      "          238,   339,   434,  4094,   278,   137,  2774,     5,  1838,   278,\n",
      "         8116,   637,  4479,     5,   209,   501, 10486,    94,   969,  8487,\n",
      "          215,    65,   121,  1941,   596,   233,  3488,  7161,   349,  6181])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(tokens, dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3488, 7161,  349, 5685,  408, 5738,  678, 3131,    5])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(train_data[:block_size+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens = list(set(tokens))\n",
    "vocab_size = len(unique_tokens)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12110"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 5\n",
    "embeds = nn.Embedding(vocab_size, embed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0955,  1.1293,  0.4822, -1.2058, -0.6945],\n",
       "        [-1.1285,  0.5376, -0.7270, -0.5792, -1.4454],\n",
       "        [-0.6640,  0.0040,  0.7976, -1.7570,  0.1647],\n",
       "        [ 0.0354, -0.9974, -1.7675,  0.5055, -0.4660],\n",
       "        [-0.4685, -0.8378,  1.4380,  0.6492, -0.8009],\n",
       "        [-1.7285, -0.7581, -0.1139, -0.0851,  0.0438],\n",
       "        [-0.7459, -3.4173, -0.7927,  0.1880,  0.1063],\n",
       "        [-0.4173,  0.9136,  0.3821, -0.1080, -0.1367],\n",
       "        [-0.5877, -0.2802,  0.3289,  0.1856, -0.0176],\n",
       "        [-0.5717, -0.1055,  0.9487,  1.4674, -1.1212]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only works with strings from shakespeare, due to limited tokens\n",
    "my_str = \"Before we proceed any further, hear me speak.\"\n",
    "embeds(torch.tensor([old2new[x] for x in enc.encode(my_str)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 2\n",
    "embedding_dim = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(s):\n",
    "    return [old2new[x] for x in enc.encode(s)]\n",
    "\n",
    "def decode(s):\n",
    "    return enc.decode([new2old[x] for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = [\n",
    "    (\n",
    "        train_data[i - context_size:i],\n",
    "        train_data[i]\n",
    "    ) for i in range(context_size, len(train_data)//100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([3488, 7161]), tensor(349)),\n",
       " (tensor([7161,  349]), tensor(5685)),\n",
       " (tensor([ 349, 5685]), tensor(408)),\n",
       " (tensor([5685,  408]), tensor(5738))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2714"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[191, 140]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"thou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([349])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(349).view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(vocab_size, embedding_dim, context_size)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"embedding_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent done w/ epoch: 0.0\n",
      "epoch 0 loss: 25284.066875457764\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 1 loss: 24546.339502334595\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 2 loss: 23708.1665725708\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 3 loss: 22777.464068889618\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 4 loss: 21875.829502224922\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 5 loss: 21077.029460787773\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 6 loss: 20386.74539422989\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 7 loss: 19792.52147525549\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 8 loss: 19270.021094292402\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 9 loss: 18793.828703939915\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 10 loss: 18352.76360039413\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 11 loss: 17943.050711661577\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 12 loss: 17561.66039097309\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 13 loss: 17204.89176040888\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 14 loss: 16870.611566111445\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 15 loss: 16557.886550411582\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 16 loss: 16264.672364525497\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 17 loss: 15987.591635294259\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 18 loss: 15723.062956906855\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 19 loss: 15468.023755148053\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 20 loss: 15220.27404858917\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 21 loss: 14978.148690514266\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 22 loss: 14740.716402329504\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 23 loss: 14507.391631715\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 24 loss: 14277.810786686838\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 25 loss: 14051.625553838909\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 26 loss: 13828.45715457946\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 27 loss: 13607.97992169112\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 28 loss: 13389.929289400578\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 29 loss: 13174.016318269074\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 30 loss: 12960.001424849033\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 31 loss: 12747.831621348858\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 32 loss: 12537.564841475338\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 33 loss: 12329.226635932922\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 34 loss: 12122.903423625976\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 35 loss: 11918.686637371778\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 36 loss: 11716.681489992887\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 37 loss: 11516.951645717025\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 38 loss: 11319.492883346975\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 39 loss: 11124.248989727348\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 40 loss: 10931.323956947774\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 41 loss: 10740.720794890076\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 42 loss: 10552.450463749468\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 43 loss: 10366.522209299728\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 44 loss: 10182.970258468762\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 45 loss: 10001.887902824208\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 46 loss: 9823.258316647261\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 47 loss: 9647.139730101451\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 48 loss: 9473.592439742759\n",
      "percent done w/ epoch: 0.0\n",
      "epoch 49 loss: 9302.770870240405\n",
      "[25284.066875457764, 24546.339502334595, 23708.1665725708, 22777.464068889618, 21875.829502224922, 21077.029460787773, 20386.74539422989, 19792.52147525549, 19270.021094292402, 18793.828703939915, 18352.76360039413, 17943.050711661577, 17561.66039097309, 17204.89176040888, 16870.611566111445, 16557.886550411582, 16264.672364525497, 15987.591635294259, 15723.062956906855, 15468.023755148053, 15220.27404858917, 14978.148690514266, 14740.716402329504, 14507.391631715, 14277.810786686838, 14051.625553838909, 13828.45715457946, 13607.97992169112, 13389.929289400578, 13174.016318269074, 12960.001424849033, 12747.831621348858, 12537.564841475338, 12329.226635932922, 12122.903423625976, 11918.686637371778, 11716.681489992887, 11516.951645717025, 11319.492883346975, 11124.248989727348, 10931.323956947774, 10740.720794890076, 10552.450463749468, 10366.522209299728, 10182.970258468762, 10001.887902824208, 9823.258316647261, 9647.139730101451, 9473.592439742759, 9302.770870240405]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    for i, (context, target) in enumerate(ngrams):\n",
    "\n",
    "        if i % eval_interval == 0:\n",
    "            print(f\"percent done w/ epoch: {i/len(ngrams)}\")\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = context\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, target.view(1))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "\n",
    "    print(f\"epoch {epoch} loss: {total_loss}\")\n",
    "print(losses)  # The loss decreased every iteration over the training data!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"embedding_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5685]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Before\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6201, -0.4573,  1.1093,  0.8587, -0.7115, -0.6778, -0.8076, -1.2620,\n",
      "         -0.6081,  0.3496]], grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To get the embedding of a particular word, e.g. \"beauty\"\n",
    "print(model.embeddings.weight[encode(\"Before\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1101, -0.3134,  1.4419,  1.5636,  0.1379, -1.6653, -0.1676,  0.4602,\n",
       "          1.1939,  0.5346],\n",
       "        [-0.2401,  1.8910,  1.4143,  0.6424,  1.7328, -2.9237, -0.3027, -1.7330,\n",
       "         -0.4693,  0.7559]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight[encode(\"king\")] - model.embeddings.weight[encode(\"prince\")]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
